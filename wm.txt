What is a world model?
An AI that generates interactive environments frame-by-frame as you move through them. Not a 3D engine — pure pixel prediction. Each frame is predicted from previous frames plus your action input. Physics, lighting, object permanence are all learned from video data, not simulated. No meshes, no pre-built assets, no game logic — everything is generated on the fly.
The landscape — three frontrunners:
Genie 3 (Google DeepMind) — Closed. Released January 2026 via Project Genie. Real-time at 20–24 fps, 720p, but capped at 60-second sessions. Requires Google AI Ultra at $250/month. No paper, no weights published.
LingBot-World (Robbyant) — Partially open. 28B parameters (14B active, MoE architecture). Claims 720p at 16 fps with the Fast model, but only the Base (camera-only) model has been released. That Base model takes 47 minutes to generate 10 seconds of video on 8×A100s. The Fast and Action-conditioned models are still pending release.
HY-World 1.5 (Tencent) — Open source and the most practically accessible right now. 8B model built on HunyuanVideo. 480p, 24 fps real-time. Runs on 28GB VRAM with 8-way sequence parallelism (so 8×RTX 3090/4090 works). Training code included. Distilled model available now.
Also notable — Runway GWM-1:
Announced December 2025, built on Gen-4.5 (top-rated video model). Autoregressive, 24 fps, 720p. Three variants: GWM Worlds (explorable environments, spatial consistency, infinite navigation), GWM Robotics (synthetic training data for robots, counterfactual simulation), GWM Avatars (conversational characters with realistic expressions and lip-sync). Runway claims it's "more general" than Genie 3 but no independent benchmarks exist to compare. Key issue: almost two months after announcement, still no public access. Robotics SDK is request-only waitlist. No paper, no weights, no benchmarks. NVIDIA Vera Rubin partnership announced.
Demos vs. reality:
Demos show photorealistic environments from text, smooth real-time navigation, emergent physics, diverse styles, memory of visited areas. What you actually get: Genie 3 has a 60-sec cap behind a $250/mo paywall. LingBot-World's fast model isn't released, and the base model is unusably slow. HY-World is the most complete but limited to 480p. All models drift over extended generation. Actions are limited to basic WASD navigation. No fine-grained object interaction.
Shared limitations across all models:
These are paradigm-level problems, not individual model weaknesses. Drift — environments degrade over time, consistency fades after seconds to minutes, not hours. Memory is emergent — no explicit 3D representation, the model "remembers" through learned patterns, not stored geometry. Narrow actions — mostly camera movement, no picking up objects, opening doors, or complex interaction. Compute cost — real-time requires distillation plus multi-GPU setups, full-quality models are far too slow for interaction. No ground truth — plausible-looking but not physically accurate, can't replace simulation engines. Also worth noting: no formal research papers published for Genie 2, Genie 3, or LingBot-World-Fast. Evaluation is largely based on demo videos and blog posts.
Why it matters:
Near-term: rapid prototyping for game environments, training data for robotics and embodied AI, concept art exploration, interactive education, architectural walkthroughs. Bigger picture: Google frames this as a stepping stone to AGI. Agents that understand cause and effect. Unlimited training environments on demand. Convergence with video generation (Veo, Sora, etc.). Key signal — this space went from research curiosity to consumer product in under two years (Genie 1 paper February 2024 → Project Genie launch January 2026).
Bottom line:
World models generate explorable environments from text/images using autoregressive video prediction, no 3D engine required. Genie 3 is the most polished but completely closed. HY-World 1.5 is the most practically usable open model right now. LingBot-World has potential but key components are unreleased. Runway GWM-1 is impressive on paper but hasn't shipped. The paradigm has fundamental unsolved problems — drift, narrow actions, no physics guarantees — but the pace of progress is rapid.
Links:
Genie 3 → deepmind.google/models/genie
LingBot-World → github.com/robbyant/lingbot-world
HY-World 1.5 → github.com/Tencent-Hunyuan/HY-WorldPlay
